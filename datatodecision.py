# -*- coding: utf-8 -*-
"""DataToDecision

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nXHg2OVO5tjoUhlV6thIUtU7exWw89bo
"""

!pip install scikit-surprise

import warnings
warnings.filterwarnings('ignore')

# Data handling and visualization
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Statistical analysis and preprocessing
from scipy.stats import norm, stats
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    roc_auc_score, confusion_matrix, accuracy_score, f1_score,
    roc_curve, classification_report, precision_score, recall_score)

# Cosine similarity and sparse matrices
from sklearn.metrics.pairwise import cosine_similarity
from scipy.sparse import csr_matrix
from sklearn.neighbors import NearestNeighbors

# Surprise library for recommendation systems
from surprise import Reader, Dataset, SVD, SVDpp, NMF, SlopeOne, CoClustering, accuracy
from surprise.model_selection import cross_validate, train_test_split
from surprise import accuracy

# Other utilities
from collections import defaultdict
import ast
import matplotlib

import pandas as pd
# Load datasets
path = "/content/Amazon Sale Report.csv"

# Load datasets
df = pd.read_csv(path)

# Print confirmation
print("Datasets Loaded Successfully!")

# Check for missing values
print("Missing values in Users data:")
print(df.isnull().sum())

df = df[df['fulfilled-by'].notna()]
df = df[df['Unnamed: 22'].notna()]
df = df[df['Amount'].notna()]
df = df[df['currency'].notna()]
df = df[df['ship-state'].notna()]
df = df[df['ship-city'].notna()]
df = df[df['promotion-ids'].notna()]

print("Missing values in Users data:")
print(df.isnull().sum())

df = df.drop('SKU', axis=1)

df = df.drop('Courier Status', axis=1)

df = df.drop('ship-service-level', axis=1)

df = df.drop('Sales Channel ', axis=1)

df = df.drop('Style', axis=1)

# Save cleaned DataFrame to CSV
df.to_csv('cleaned_data.csv', index=False)

# Download the file to your local system
from google.colab import files
files.download('cleaned_data.csv')

# Check for duplicates
print(f"Duplicates in dataset: {df.duplicated().sum()}")

# Descriptive stats for Amount of product
print("Sales Dataset:")
print(df['Amount'].describe())

import pandas as pd
df=pd.read_csv('/content/cleaned_data.csv')
df['Amount'] = df['Amount'].astype(int)
print("Column Updated !\n")
print(df)

Q1 = df['Amount'].quantile(0.25)
Q3 = df['Amount'].quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

amount_outliers = df[(df['Amount'] < lower_bound) | (df['Amount'] > upper_bound)]

print("üìå Amount Outliers:")
print(amount_outliers[['Order ID','Category', 'Amount']])
print(f"Total Amount Outliers: {len(amount_outliers)}\n")

df.describe()

# Keep only rows where Amount is less than or equal to 2796
df = df[df['Amount'] <=2796]

print("‚úÖ Kept rows where Amount is less than or equal to 2796.")
print(f"üìö Remaining rows: {df.shape[0]}")

import matplotlib.pyplot as plt
plt.subplot(1, 1, 1)
df['Category'].hist(bins=30, color='salmon', edgecolor='black')
plt.title(' After Cleaning (<= 2796)')
plt.xlabel('Category')
plt.ylabel('Amount')

plt.tight_layout()
plt.show()

import seaborn as sns
sns.histplot(df['Amount'], kde=True)
plt.title('Sales Analysis (Histogram)')
plt.show()

numerical_cols = df.select_dtypes(include='number').columns
if len(numerical_cols) > 1:
    plt.figure(figsize=(8, 6))
    correlation_matrix = df[numerical_cols].dropna().corr()
    if not correlation_matrix.empty:
        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
        plt.title('Correlation Matrix (Heatmap)')
        plt.show()
    else:
        print("Correlation matrix is empty. Check your dataset.")

user_stats = df.groupby('Amount')['Amount'].agg(['count', 'mean']).reset_index()
plt.xlim(0, 1000)  # Or adjust based on your data

sns.scatterplot(data=user_stats, x='count', y='mean', alpha=0.5)
plt.title("Number of Ratings per User vs Average Rating")
plt.xlabel("Number of Ratings")
plt.ylabel("Average Rating")
plt.show()

import pandas as pd
df=pd.read_csv('/content/cleaned_data.csv')

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

df['Amount'] = pd.to_numeric(df['Amount'], errors='coerce')
df_clean = df.dropna(subset=['Amount'])
df_clean = df_clean[(df_clean['Amount'] >= 0) &
                                (df_clean['Amount'] <= 2796)]
plt.figure(figsize=(10, 5))
sns.boxplot(x=df_clean['Amount'])
plt.title('üì¶ Box Plot of Year Of Publication (Cleaned)')
plt.xlabel('Year')
plt.show()

import pandas as pd

# Group by category and sum the quantity
category_totals = df.groupby('Category')['Qty'].sum().reset_index()

# Optional: Sort by total quantity (descending)
category_totals = category_totals.sort_values(by='Qty', ascending=False)

# Display result
print(category_totals)

import matplotlib.pyplot as plt

# Group by category and sum quantity
category_totals = df.groupby('Category')['Qty'].sum().reset_index()

# Sort categories by total quantity
category_totals = category_totals.sort_values(by='Qty', ascending=False)

# Plotting the bar chart
plt.figure(figsize=(10, 6))
plt.bar(category_totals['Category'], category_totals['Qty'], color='skyblue')
plt.xlabel('Clothing Category')
plt.ylabel('Total Quantity Sold')
plt.title('Total Clothes Sold per Category')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

state_totals = df.groupby('ship-state')['Qty'].sum().reset_index()

# Sort by quantity sold (descending)
state_totals = state_totals.sort_values(by='Qty', ascending=False)

# Display top states
print(state_totals.head())

# Optional: Bar chart of top 10 states
plt.figure(figsize=(10, 6))
plt.bar(state_totals['ship-state'][:10], state_totals['Qty'][:10], color='green')
plt.xlabel('State')
plt.ylabel('Total Clothes Sold')
plt.title('Top States by Clothes Sold')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

maharashtra_df = df[df['ship-state'] == 'MAHARASHTRA']

# Group by city and sum quantity
city_totals = maharashtra_df.groupby('ship-city')['Qty'].sum().reset_index()
city_totals = city_totals.sort_values(by='Qty', ascending=False).head(15)

# Set plot size and style
plt.figure(figsize=(10, 6))
sns.set(style="whitegrid")

# Barplot
sns.barplot(data=city_totals, x='ship-city', y='Qty', palette='Set3')  # Try 'Set3', 'husl', 'pastel', etc.

# Customize labels
plt.xlabel('City in Maharashtra')
plt.ylabel('Total Clothes Sold')
plt.title('Top Cities in Maharashtra by Clothes Sold')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

arunachal_df = df[df['ship-state'] == 'ARUNACHAL PRADESH']

# Group by city and sum quantity
city_totals = arunachal_df.groupby('ship-city')['Qty'].sum().reset_index()

# Sort by quantity (ascending)
city_totals = city_totals.sort_values(by='Qty')

# Print the city with the least clothes delivered
least_city = city_totals.iloc[0]
print(f"üìâ City with the least clothes delivered in Arunachal Pradesh: {least_city['ship-city']} ({least_city['Qty']} items)")

# Optional: Plot all cities in Arunachal Pradesh
plt.figure(figsize=(8, 5))
sns.set(style="whitegrid")
sns.barplot(data=city_totals, x='ship-city', y='Qty', palette='Blues_r')
plt.title('City-wise Clothes Delivery in Arunachal Pradesh')
plt.xlabel('City')
plt.ylabel('Total Clothes Delivered')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

size_totals = df.groupby('Size')['Qty'].sum().reset_index()

# Sort by quantity
size_totals = size_totals.sort_values(by='Qty', ascending=False)

# Plot
plt.figure(figsize=(8, 5))
sns.set(style="whitegrid")
sns.barplot(data=size_totals, x='Size', y='Qty', palette='coolwarm')

# Labels and title
plt.xlabel('Clothing Size')
plt.ylabel('Total Quantity Sold')
plt.title('Most Sold Clothing Sizes')
plt.tight_layout()
plt.show()

from sklearn.model_selection import train_test_split

# Example: let's say you're predicting 'Amount' using other columns
# Step 1: Prepare X and y
X = df.drop('Amount', axis=1)   # Features (drop target column)
y = df['Amount']                # Target variable

# Step 2: Split into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Output shapes
print("Training set:", X_train.shape)
print("Testing set:", X_test.shape)

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

df = df[['Category', 'ship-state', 'ship-city', 'Amount']]

# One-hot encode categorical columns
df_encoded = pd.get_dummies(df, columns=['Category', 'ship-state', 'ship-city'], drop_first=True)

# Split features and target
X = df_encoded.drop('Amount', axis=1)
y = df_encoded['Amount']

# Split into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a Linear Regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Predict and evaluate
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)

print("‚úÖ Model trained successfully!")
print("üìâ Mean Squared Error on test set:", mse)
y_pred = model.predict(X_test)

# Evaluation metrics
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

# Print results
print("üìä Model Evaluation Metrics:")
print(f"üîπ Mean Absolute Error (MAE): {mae:.2f}")
print(f"üîπ Mean Squared Error (MSE): {mse:.2f}")
print(f"üîπ Root Mean Squared Error (RMSE): {rmse:.2f}")
print(f"üîπ R¬≤ Score: {r2:.4f}")

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

# Train a Random Forest model
model_rf = RandomForestRegressor(n_estimators=100, random_state=42)
model_rf.fit(X_train, y_train)

# Predict on test set
y_pred_rf = model_rf.predict(X_test)

# Evaluate the model
mae_rf = mean_absolute_error(y_test, y_pred_rf)
mse_rf = mean_squared_error(y_test, y_pred_rf)
rmse_rf = np.sqrt(mse_rf)
r2_rf = r2_score(y_test, y_pred_rf)

# Print results
print("üìä Random Forest Model Evaluation Metrics:")
print(f"üîπ Mean Absolute Error (MAE): {mae_rf:.2f}")
print(f"üîπ Mean Squared Error (MSE): {mse_rf:.2f}")
print(f"üîπ Root Mean Squared Error (RMSE): {rmse_rf:.2f}")
print(f"üîπ R¬≤ Score: {r2_rf:.4f}")

import pandas as pd
df=pd.read_csv('/content/cleaned_data.csv')

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import GradientBoostingClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

df = df[['Category', 'Amount', 'Qty', 'ship-state']]  # Adjust if you have more/less columns

# üéØ Create a target variable ‚Äî you can modify the logic!
df['WillBuy'] = df['Amount'].apply(lambda x: 1 if x >= 1000 else 0)

# üîÑ Encode categorical features
label_encoders = {}
for col in ['Category', 'ship-state']:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le

# üîç Features and target
X = df.drop('WillBuy', axis=1)
y = df['WillBuy']

# ‚úÇÔ∏è Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# -----------------------------------------------
# ‚úÖ Gradient Boosting Classifier
gb_model = GradientBoostingClassifier()
gb_model.fit(X_train, y_train)
gb_preds = gb_model.predict(X_test)

print("üìà Gradient Boosting Results:")
print("Accuracy:", accuracy_score(y_test, gb_preds))
print(confusion_matrix(y_test, gb_preds))
print(classification_report(y_test, gb_preds))

# -----------------------------------------------
# ‚úÖ XGBoost Classifier
xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')
xgb_model.fit(X_train, y_train)
xgb_preds = xgb_model.predict(X_test)

print("‚ö° XGBoost Results:")
print("Accuracy:", accuracy_score(y_test, xgb_preds))
print(confusion_matrix(y_test, xgb_preds))
print(classification_report(y_test, xgb_preds))

import pandas as pd
import matplotlib.pyplot as plt

# Create DataFrame with evaluation metrics
data = {
    'Model': ['Random Forest (Reg)', 'Gradient Boosting (Cls)', 'XGBoost (Cls)'],
    'MAE': [174.98, None, None],
    'MSE': [63067.36, None, None],
    'RMSE': [251.13, None, None],
    'R2 Score': [0.2636, None, None],
    'Accuracy': [None, 1.0, 1.0],
    'Precision (1)': [None, 1.0, 1.0],
    'Recall (1)': [None, 1.0, 1.0],
    'F1 Score (1)': [None, 1.0, 1.0],
}

comparison_df = pd.DataFrame(data)
print("üìä Model Comparison Table:")
print(comparison_df)


# Plotting the comparison
plt.figure(figsize=(12, 5))

# R¬≤ Score (Regression metric)
plt.subplot(1, 2, 1)
r2_values = [0.2636, 0, 0]
plt.bar(data['Model'], r2_values, color=['skyblue', 'gray', 'gray'])
plt.title('R¬≤ Score Comparison')
plt.ylabel('Score')
plt.ylim(0, 1)

# Accuracy (Classification metric)
plt.subplot(1, 2, 2)
accuracy_values = [0, 1.0, 1.0]
plt.bar(data['Model'], accuracy_values, color=['gray', 'green', 'orange'])
plt.title('Accuracy Comparison')
plt.ylabel('Score')
plt.ylim(0, 1)

plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Input from user
category_input = input("Enter the clothing category: ").strip().upper()

# Convert 'Category' column to string to avoid .str error
df['Category'] = df['Category'].astype(str)

# Filter the DataFrame by category
filtered_df = df[df['Category'].str.upper() == category_input]

# Check if any data found
if filtered_df.empty:
    print(f"‚ùå No data found for category: {category_input}")
else:
    # Group by size
    size_totals = filtered_df.groupby('Size')['Qty'].sum().reset_index()
    most_sold_size = size_totals.sort_values(by='Qty', ascending=False).iloc[0]
    least_sold_size = size_totals.sort_values(by='Qty', ascending=True).iloc[0]

    # Group by state
    state_totals = filtered_df.groupby('ship-state')['Qty'].sum().reset_index()
    most_sold_state = state_totals.sort_values(by='Qty', ascending=False).iloc[0]
    least_sold_state = state_totals.sort_values(by='Qty', ascending=True).iloc[0]

    # Group by city
    city_totals = filtered_df.groupby('ship-city')['Qty'].sum().reset_index()
    most_sold_city = city_totals.sort_values(by='Qty', ascending=False).iloc[0]

    # Get a city with the lowest sales in the least sold state
    state_city_df = filtered_df[filtered_df['ship-state'] == least_sold_state['ship-state']]
    city_in_least_state = state_city_df.groupby('ship-city')['Qty'].sum().reset_index()
    lowest_city_in_least_state = city_in_least_state.sort_values(by='Qty').iloc[0]

    # Print results
    print(f"\nüìä Analysis for Category: {category_input}")
    print(f"üëï Most sold size: {most_sold_size['Size']} ({most_sold_size['Qty']} units)")
    print(f"üîª Least sold size: {least_sold_size['Size']} ({least_sold_size['Qty']} units)")
    print(f"üìç State with highest sales: {most_sold_state['ship-state']} ({most_sold_state['Qty']} units)")
    print(f"üìâ State with lowest sales: {least_sold_state['ship-state']} ({least_sold_state['Qty']} units)")
    print(f"üèôÔ∏è City with highest sales: {most_sold_city['ship-city']} ({most_sold_city['Qty']} units)")
    print(f"üìå City with lowest sales in {least_sold_state['ship-state']}: {lowest_city_in_least_state['ship-city']} ({lowest_city_in_least_state['Qty']} units)")

 # ---------- PLOTTING GRAPHS ---------- #

    # Size vs Qty
    plt.figure(figsize=(6, 4))
    plt.bar(size_totals['Size'], size_totals['Qty'], color='teal')
    plt.title(f"Clothing Sizes Sold - {category_input}")
    plt.xlabel("Size")
    plt.ylabel("Quantity Sold")
    plt.tight_layout()
    plt.show()

    # State vs Qty
    plt.figure(figsize=(10, 5))
    plt.bar(state_totals['ship-state'], state_totals['Qty'], color='slateblue')
    plt.title(f"Sales by State - {category_input}")
    plt.xlabel("State")
    plt.ylabel("Quantity Sold")
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

    # Top 10 cities by sales
    top_10_cities = city_totals.sort_values(by='Qty', ascending=False).head(10)
    plt.figure(figsize=(10, 5))
    plt.bar(top_10_cities['ship-city'], top_10_cities['Qty'], color='salmon')
    plt.title(f"Top 10 Cities by Sales - {category_input}")
    plt.xlabel("City")
    plt.ylabel("Quantity Sold")
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()